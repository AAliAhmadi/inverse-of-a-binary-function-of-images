{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "BhgSJrVQVFuj"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "QQdJCL30VMvg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vssi90-HXGae",
    "outputId": "92127642-1bf1-46ec-9dfa-e62c0547aa24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset= torchvision.datasets.CIFAR10(root=',', train= True, \n",
    "                                 transform= normalize_transform , download= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "JGBn7v1FXGd0"
   },
   "outputs": [],
   "source": [
    "(train_image, train_label)= train_dataset.data, train_dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iIcRJxnGXGgj"
   },
   "outputs": [],
   "source": [
    "#making a dataframe of train images of CIFAR10\n",
    "import pandas as pd\n",
    "df= pd.DataFrame(list(zip(train_dataset.data, train_label)), columns= ['image', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7X8tjoPuXGj6"
   },
   "outputs": [],
   "source": [
    "#taking a random sample of CIFAR10\n",
    "sett= df.sample(n=1000, replace= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6ngtmUjoZuAJ",
    "outputId": "6c52b34b-55a1-4e23-dbac-f2fceb958618"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a4d0d8a5-db5d-4a29-9a39-d819b79e0968\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[211, 190, 147], [212, 190, 146], [208, 187,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[246, 255, 248], [246, 250, 241], [149, 140,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[89, 83, 55], [77, 72, 44], [99, 94, 66], [1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[11, 4, 20], [11, 4, 20], [11, 4, 20], [11, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[105, 115, 127], [103, 113, 125], [108, 117,...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4d0d8a5-db5d-4a29-9a39-d819b79e0968')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a4d0d8a5-db5d-4a29-9a39-d819b79e0968 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a4d0d8a5-db5d-4a29-9a39-d819b79e0968');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  [[[211, 190, 147], [212, 190, 146], [208, 187,...  3\n",
       "1  [[[246, 255, 248], [246, 250, 241], [149, 140,...  5\n",
       "2  [[[89, 83, 55], [77, 72, 44], [99, 94, 66], [1...  0\n",
       "3  [[[11, 4, 20], [11, 4, 20], [11, 4, 20], [11, ...  0\n",
       "4  [[[105, 115, 127], [103, 113, 125], [108, 117,...  8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making a dataframe using these 1000 samples\n",
    "Sett= pd.DataFrame(sett.values, index= np.arange(0,1000))\n",
    "Sett.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pO67P75Gzq4g"
   },
   "source": [
    "I define a function called cartesian to make cartesian products of images. Later, I use it to compute the middle of each two images and then drop the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ruf5OK85Xueb"
   },
   "outputs": [],
   "source": [
    "def cartesian(*arrays):\n",
    "    mesh = np.meshgrid(*arrays)  # Standard NumPy meshgrid\n",
    "    dim = len(mesh)  # Number of dimensions\n",
    "    elements = mesh[0].size  # Number of elements, any index will do\n",
    "    flat = np.concatenate(mesh).ravel()  # Flatten the whole meshgrid\n",
    "    reshape = np.reshape(flat, (dim, elements)).T  # Reshape and transpose\n",
    "    return reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvW8j1101iyk"
   },
   "source": [
    "For this simple task, 150 images of CIFAR10 is surely enough. But for harder task, I could use much more data to train the network.\n",
    "Another reason for using this small set of images is that my cpu is a little weak and even using google colab, I got run time error that buy a new cpu for task when I use the entire images.\n",
    "\n",
    "I can still make a very good predictig function for all our 1000 samples in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-l9BHCSgZuDQ"
   },
   "outputs": [],
   "source": [
    "AS= Sett[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "E8iZeaZV_UaU"
   },
   "outputs": [],
   "source": [
    "S= Sett[0][:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mC5kugeHZnt-",
    "outputId": "d7293405-3be8-4605-fad3-6124e4306c62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making catrtesian product of 150 images\n",
    "f= cartesian(S, S)\n",
    "len(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FdfYneTvZnw7"
   },
   "outputs": [],
   "source": [
    "#making data frame of theis cartesian so that I have a dataframe of two columns which is \n",
    "#the cartesian product of each combination of two images. But, here still have both (A,B), (B,A) in\n",
    "ourdata= pd.DataFrame(data= f, columns= ('output1', 'output2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emdyNS_A4NBg"
   },
   "source": [
    "making data frame of theis cartesian so that I have a dataframe of two columns which is the cartesian product of each combination of two images. But here, we have both (A,B), (B,A) in dataframe that is undesired because it produces duplicates for middle ones. The reason why I am using dataframe is because I want to use drop.duplicates command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SwCL76n1Znze"
   },
   "outputs": [],
   "source": [
    "#Here, I flattened the values of this dataframe and computed the middle of two images\n",
    "A= [ourdata['output1'][i].flatten() for i in range(len(f))]\n",
    "B= [ourdata['output2'][i].flatten() for i in range(len(f))]\n",
    "C= [A[i]/2+B[i]/2 for i in range(len(f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "AKEjiMGbalZR",
    "outputId": "26c98dfc-a2e4-4b3f-f4fb-39aa7ab7f44f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3adf3f65-0d73-4499-bdcf-d72c27b3357b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output1</th>\n",
       "      <th>output2</th>\n",
       "      <th>middle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[211, 190, 147, 212, 190, 146, 208, 187, 143, ...</td>\n",
       "      <td>[211, 190, 147, 212, 190, 146, 208, 187, 143, ...</td>\n",
       "      <td>[211.0, 190.0, 147.0, 212.0, 190.0, 146.0, 208...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[246, 255, 248, 246, 250, 241, 149, 140, 122, ...</td>\n",
       "      <td>[211, 190, 147, 212, 190, 146, 208, 187, 143, ...</td>\n",
       "      <td>[228.5, 222.5, 197.5, 229.0, 220.0, 193.5, 178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[89, 83, 55, 77, 72, 44, 99, 94, 66, 179, 175,...</td>\n",
       "      <td>[211, 190, 147, 212, 190, 146, 208, 187, 143, ...</td>\n",
       "      <td>[150.0, 136.5, 101.0, 144.5, 131.0, 95.0, 153....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[11, 4, 20, 11, 4, 20, 11, 4, 20, 11, 4, 20, 1...</td>\n",
       "      <td>[211, 190, 147, 212, 190, 146, 208, 187, 143, ...</td>\n",
       "      <td>[111.0, 97.0, 83.5, 111.5, 97.0, 83.0, 109.5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[105, 115, 127, 103, 113, 125, 108, 117, 129, ...</td>\n",
       "      <td>[211, 190, 147, 212, 190, 146, 208, 187, 143, ...</td>\n",
       "      <td>[158.0, 152.5, 137.0, 157.5, 151.5, 135.5, 158...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3adf3f65-0d73-4499-bdcf-d72c27b3357b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3adf3f65-0d73-4499-bdcf-d72c27b3357b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3adf3f65-0d73-4499-bdcf-d72c27b3357b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                             output1  \\\n",
       "0  [211, 190, 147, 212, 190, 146, 208, 187, 143, ...   \n",
       "1  [246, 255, 248, 246, 250, 241, 149, 140, 122, ...   \n",
       "2  [89, 83, 55, 77, 72, 44, 99, 94, 66, 179, 175,...   \n",
       "3  [11, 4, 20, 11, 4, 20, 11, 4, 20, 11, 4, 20, 1...   \n",
       "4  [105, 115, 127, 103, 113, 125, 108, 117, 129, ...   \n",
       "\n",
       "                                             output2  \\\n",
       "0  [211, 190, 147, 212, 190, 146, 208, 187, 143, ...   \n",
       "1  [211, 190, 147, 212, 190, 146, 208, 187, 143, ...   \n",
       "2  [211, 190, 147, 212, 190, 146, 208, 187, 143, ...   \n",
       "3  [211, 190, 147, 212, 190, 146, 208, 187, 143, ...   \n",
       "4  [211, 190, 147, 212, 190, 146, 208, 187, 143, ...   \n",
       "\n",
       "                                              middle  \n",
       "0  [211.0, 190.0, 147.0, 212.0, 190.0, 146.0, 208...  \n",
       "1  [228.5, 222.5, 197.5, 229.0, 220.0, 193.5, 178...  \n",
       "2  [150.0, 136.5, 101.0, 144.5, 131.0, 95.0, 153....  \n",
       "3  [111.0, 97.0, 83.5, 111.5, 97.0, 83.0, 109.5, ...  \n",
       "4  [158.0, 152.5, 137.0, 157.5, 151.5, 135.5, 158...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_data= pd.DataFrame({'output1':A, 'output2':B, 'middle':C})\n",
    "our_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "QhPCXRPuw3pl"
   },
   "outputs": [],
   "source": [
    "#Here, drop duplicates for the column 'middle'\n",
    "new_data = our_data[~our_data['middle'].apply(tuple).duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "vAbtawYaalh8",
    "outputId": "53d972c4-c4ec-432f-ba5b-34183ccd34ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6afbf96b-af00-4eda-be9b-33df84187098\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output1</th>\n",
       "      <th>output2</th>\n",
       "      <th>middle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[211, 190, 147, 212, 190, 146, 208, 187, 143, ...</td>\n",
       "      <td>[211, 190, 147, 212, 190, 146, 208, 187, 143, ...</td>\n",
       "      <td>[211.0, 190.0, 147.0, 212.0, 190.0, 146.0, 208...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[246, 255, 248, 246, 250, 241, 149, 140, 122, ...</td>\n",
       "      <td>[211, 190, 147, 212, 190, 146, 208, 187, 143, ...</td>\n",
       "      <td>[228.5, 222.5, 197.5, 229.0, 220.0, 193.5, 178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[89, 83, 55, 77, 72, 44, 99, 94, 66, 179, 175,...</td>\n",
       "      <td>[211, 190, 147, 212, 190, 146, 208, 187, 143, ...</td>\n",
       "      <td>[150.0, 136.5, 101.0, 144.5, 131.0, 95.0, 153....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[11, 4, 20, 11, 4, 20, 11, 4, 20, 11, 4, 20, 1...</td>\n",
       "      <td>[211, 190, 147, 212, 190, 146, 208, 187, 143, ...</td>\n",
       "      <td>[111.0, 97.0, 83.5, 111.5, 97.0, 83.0, 109.5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[105, 115, 127, 103, 113, 125, 108, 117, 129, ...</td>\n",
       "      <td>[211, 190, 147, 212, 190, 146, 208, 187, 143, ...</td>\n",
       "      <td>[158.0, 152.5, 137.0, 157.5, 151.5, 135.5, 158...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6afbf96b-af00-4eda-be9b-33df84187098')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6afbf96b-af00-4eda-be9b-33df84187098 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6afbf96b-af00-4eda-be9b-33df84187098');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                             output1  \\\n",
       "0  [211, 190, 147, 212, 190, 146, 208, 187, 143, ...   \n",
       "1  [246, 255, 248, 246, 250, 241, 149, 140, 122, ...   \n",
       "2  [89, 83, 55, 77, 72, 44, 99, 94, 66, 179, 175,...   \n",
       "3  [11, 4, 20, 11, 4, 20, 11, 4, 20, 11, 4, 20, 1...   \n",
       "4  [105, 115, 127, 103, 113, 125, 108, 117, 129, ...   \n",
       "\n",
       "                                             output2  \\\n",
       "0  [211, 190, 147, 212, 190, 146, 208, 187, 143, ...   \n",
       "1  [211, 190, 147, 212, 190, 146, 208, 187, 143, ...   \n",
       "2  [211, 190, 147, 212, 190, 146, 208, 187, 143, ...   \n",
       "3  [211, 190, 147, 212, 190, 146, 208, 187, 143, ...   \n",
       "4  [211, 190, 147, 212, 190, 146, 208, 187, 143, ...   \n",
       "\n",
       "                                              middle  \n",
       "0  [211.0, 190.0, 147.0, 212.0, 190.0, 146.0, 208...  \n",
       "1  [228.5, 222.5, 197.5, 229.0, 220.0, 193.5, 178...  \n",
       "2  [150.0, 136.5, 101.0, 144.5, 131.0, 95.0, 153....  \n",
       "3  [111.0, 97.0, 83.5, 111.5, 97.0, 83.0, 109.5, ...  \n",
       "4  [158.0, 152.5, 137.0, 157.5, 151.5, 135.5, 158...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "rZ864DBTallK",
    "outputId": "bdd0d7e1-c632-4584-fd4b-10999d775ef2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e3623da3-25e6-4d28-a98f-0d5fb7d0cf9e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output1</th>\n",
       "      <th>output2</th>\n",
       "      <th>middle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[221, 211, 210, 222, 212, 211, 222, 211, 209, ...</td>\n",
       "      <td>[111, 105, 108, 117, 114, 109, 126, 126, 120, ...</td>\n",
       "      <td>[166.0, 158.0, 159.0, 169.5, 163.0, 160.0, 174...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 4, 0, 2, 5, 2, 3, 8, 16, 5, 8, 54, 22, ...</td>\n",
       "      <td>[64, 148, 186, 65, 148, 186, 67, 150, 189, 69,...</td>\n",
       "      <td>[32.0, 74.0, 95.0, 32.5, 75.0, 95.5, 34.5, 76....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[209, 195, 179, 215, 203, 186, 200, 188, 173, ...</td>\n",
       "      <td>[155, 166, 192, 157, 167, 193, 158, 168, 193, ...</td>\n",
       "      <td>[182.0, 180.5, 185.5, 186.0, 185.0, 189.5, 179...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[119, 146, 175, 121, 148, 177, 122, 149, 177, ...</td>\n",
       "      <td>[130, 122, 84, 131, 114, 85, 146, 120, 88, 152...</td>\n",
       "      <td>[124.5, 134.0, 129.5, 126.0, 131.0, 131.0, 134...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[251, 252, 250, 249, 250, 248, 249, 250, 247, ...</td>\n",
       "      <td>[0, 4, 7, 0, 4, 7, 0, 4, 7, 0, 4, 7, 0, 4, 7, ...</td>\n",
       "      <td>[125.5, 128.0, 128.5, 124.5, 127.0, 127.5, 124...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11320</th>\n",
       "      <td>[255, 255, 253, 253, 254, 249, 253, 254, 249, ...</td>\n",
       "      <td>[90, 46, 26, 96, 47, 25, 89, 35, 12, 102, 44, ...</td>\n",
       "      <td>[172.5, 150.5, 139.5, 174.5, 150.5, 137.0, 171...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11321</th>\n",
       "      <td>[17, 17, 17, 18, 18, 18, 24, 22, 22, 33, 29, 3...</td>\n",
       "      <td>[238, 237, 232, 235, 234, 228, 235, 234, 229, ...</td>\n",
       "      <td>[127.5, 127.0, 124.5, 126.5, 126.0, 123.0, 129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11322</th>\n",
       "      <td>[221, 177, 108, 230, 193, 119, 239, 206, 125, ...</td>\n",
       "      <td>[221, 211, 210, 222, 212, 211, 222, 211, 209, ...</td>\n",
       "      <td>[221.0, 194.0, 159.0, 226.0, 202.5, 165.0, 230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11323</th>\n",
       "      <td>[119, 146, 175, 121, 148, 177, 122, 149, 177, ...</td>\n",
       "      <td>[255, 255, 255, 255, 255, 255, 255, 255, 255, ...</td>\n",
       "      <td>[187.0, 200.5, 215.0, 188.0, 201.5, 216.0, 188...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11324</th>\n",
       "      <td>[209, 195, 179, 215, 203, 186, 200, 188, 173, ...</td>\n",
       "      <td>[140, 134, 136, 150, 144, 146, 156, 150, 152, ...</td>\n",
       "      <td>[174.5, 164.5, 157.5, 182.5, 173.5, 166.0, 178...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11325 rows Ã— 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3623da3-25e6-4d28-a98f-0d5fb7d0cf9e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e3623da3-25e6-4d28-a98f-0d5fb7d0cf9e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e3623da3-25e6-4d28-a98f-0d5fb7d0cf9e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                 output1  \\\n",
       "0      [221, 211, 210, 222, 212, 211, 222, 211, 209, ...   \n",
       "1      [0, 0, 4, 0, 2, 5, 2, 3, 8, 16, 5, 8, 54, 22, ...   \n",
       "2      [209, 195, 179, 215, 203, 186, 200, 188, 173, ...   \n",
       "3      [119, 146, 175, 121, 148, 177, 122, 149, 177, ...   \n",
       "4      [251, 252, 250, 249, 250, 248, 249, 250, 247, ...   \n",
       "...                                                  ...   \n",
       "11320  [255, 255, 253, 253, 254, 249, 253, 254, 249, ...   \n",
       "11321  [17, 17, 17, 18, 18, 18, 24, 22, 22, 33, 29, 3...   \n",
       "11322  [221, 177, 108, 230, 193, 119, 239, 206, 125, ...   \n",
       "11323  [119, 146, 175, 121, 148, 177, 122, 149, 177, ...   \n",
       "11324  [209, 195, 179, 215, 203, 186, 200, 188, 173, ...   \n",
       "\n",
       "                                                 output2  \\\n",
       "0      [111, 105, 108, 117, 114, 109, 126, 126, 120, ...   \n",
       "1      [64, 148, 186, 65, 148, 186, 67, 150, 189, 69,...   \n",
       "2      [155, 166, 192, 157, 167, 193, 158, 168, 193, ...   \n",
       "3      [130, 122, 84, 131, 114, 85, 146, 120, 88, 152...   \n",
       "4      [0, 4, 7, 0, 4, 7, 0, 4, 7, 0, 4, 7, 0, 4, 7, ...   \n",
       "...                                                  ...   \n",
       "11320  [90, 46, 26, 96, 47, 25, 89, 35, 12, 102, 44, ...   \n",
       "11321  [238, 237, 232, 235, 234, 228, 235, 234, 229, ...   \n",
       "11322  [221, 211, 210, 222, 212, 211, 222, 211, 209, ...   \n",
       "11323  [255, 255, 255, 255, 255, 255, 255, 255, 255, ...   \n",
       "11324  [140, 134, 136, 150, 144, 146, 156, 150, 152, ...   \n",
       "\n",
       "                                                  middle  \n",
       "0      [166.0, 158.0, 159.0, 169.5, 163.0, 160.0, 174...  \n",
       "1      [32.0, 74.0, 95.0, 32.5, 75.0, 95.5, 34.5, 76....  \n",
       "2      [182.0, 180.5, 185.5, 186.0, 185.0, 189.5, 179...  \n",
       "3      [124.5, 134.0, 129.5, 126.0, 131.0, 131.0, 134...  \n",
       "4      [125.5, 128.0, 128.5, 124.5, 127.0, 127.5, 124...  \n",
       "...                                                  ...  \n",
       "11320  [172.5, 150.5, 139.5, 174.5, 150.5, 137.0, 171...  \n",
       "11321  [127.5, 127.0, 124.5, 126.5, 126.0, 123.0, 129...  \n",
       "11322  [221.0, 194.0, 159.0, 226.0, 202.5, 165.0, 230...  \n",
       "11323  [187.0, 200.5, 215.0, 188.0, 201.5, 216.0, 188...  \n",
       "11324  [174.5, 164.5, 157.5, 182.5, 173.5, 166.0, 178...  \n",
       "\n",
       "[11325 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here, I shuffled the rows of our dataframe and called the new dataframe as 'shuffled'\n",
    "shuffled = new_data.sample(frac=1)\n",
    "shuffled = shuffled.reset_index()\n",
    "del shuffled['index']\n",
    "shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GwMtM8k3alrV",
    "outputId": "5b520b89-e18d-44d9-fe9e-26bf24bebbc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7927\n"
     ]
    }
   ],
   "source": [
    "#definig train size and test size . Our train data is .7 of the size of our data\n",
    "train_size= int(.7* len(shuffled))\n",
    "test_size= len(shuffled)- train_size\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ztnSaVd6a22"
   },
   "source": [
    "Now, I devide our data into train and test set. I use the first 7927 data for train and the rest for the test part (as our data has become shuffled, it is absolutely ok to use first indices for train and rest for test and actually I shuffled the data for this reason)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KnZrmjzdalvJ"
   },
   "outputs": [],
   "source": [
    "imag1tr= shuffled['output1'][:train_size]\n",
    "imag2tr= shuffled['output2'][:train_size]\n",
    "middtr= shuffled['middle'][:train_size]\n",
    "\n",
    "imag1te= shuffled['output1'][train_size:]\n",
    "imag2te= shuffled['output2'][train_size:]\n",
    "middte= shuffled['middle'][train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "sQPgHtI8bH0E"
   },
   "outputs": [],
   "source": [
    "#making a list af train and test data to produce dataloader\n",
    "train_data = []\n",
    "for i in range(train_size):\n",
    "    train_data.append([imag1tr[i], imag2tr[i], middtr[i]])\n",
    "\n",
    "test_data = []\n",
    "for i in range(test_size):\n",
    "    test_data.append([imag1te[train_size+i], imag2te[train_size+i], middte[train_size+i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mjt_jzzYbH3Q",
    "outputId": "45d8eeea-2f90-4c41-e6f0-1d88f90d8119"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3072])\n",
      "torch.Size([20, 3072])\n",
      "torch.Size([20, 3072])\n"
     ]
    }
   ],
   "source": [
    "#making train and test dataloader for our network\n",
    "trainloader = torch.utils.data.DataLoader(train_data, shuffle=False, batch_size=20)\n",
    "img1_tr, img2_tr, midd_tr = next(iter(trainloader))\n",
    "print(img1_tr.shape)\n",
    "print(img2_tr.shape)\n",
    "print(midd_tr.shape)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=1)\n",
    "img1_te, img2_te, midd_te = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrKIrzTp7zmv"
   },
   "source": [
    "I define the network here. As its a very simple task, I used a very simple network with very few parameters. \n",
    "The way I decided to solve this problem, is that firstly, I designed a network that learn how to produce the middle of the two images by training and backpropagating loss. It learns that:\n",
    " e((aX+b)+(cY+d))+f= Middle matrix\n",
    "where X and Y are inputs and a,b,c,d,e,f are scalers that network tried to learn. \n",
    "My idea is that then, for a simple input Z which is (X+Y)/2 for an X and Y image, network uses its learnt weights and by a function called predicting, it predicts the output of set of (X',Y')s and see which output is closer to Z. Then, it returns the (X',Y') that it thinks that corresponds to producing that Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5H895SYXbH71"
   },
   "outputs": [],
   "source": [
    "class myNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myNet, self).__init__()\n",
    "        \n",
    "        #As middle matrix is the same size as both inputs, its predictable that network can be a simple linear\n",
    "        #combination of X and Y as input. But still, could make network more complicated adding layers\n",
    "        #with different output size as hidden layers \n",
    "        \n",
    "        self.fc1 = nn.Linear(3072, 3072)  # set up FC layer for input X \n",
    "        self.fc2 = nn.Linear(3072, 3072)  # set up the other FC layer for Y\n",
    "        self.fc3 = nn.Linear(3072, 3072)  # set up the other FC layer for Z=(X+Y)/2\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        a = self.fc1(input1)\n",
    "        a.to(device)\n",
    "\n",
    "        b = self.fc2(input2)\n",
    "        b.to(device)\n",
    "        combined = a+b\n",
    "        out = self.fc3(combined)\n",
    "        out.to(device)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hv2g9HFgbVrk",
    "outputId": "92770b8f-6fba-4e6e-bb51-37b8f55470b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myNet(\n",
       "  (fc1): Linear(in_features=3072, out_features=3072, bias=True)\n",
       "  (fc2): Linear(in_features=3072, out_features=3072, bias=True)\n",
       "  (fc3): Linear(in_features=3072, out_features=3072, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model= myNet()\n",
    "model= model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ywsPJWM-bVuu"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()                            #loss function. there are alternatives as CrossEntropy loss\n",
    "optimizer= optim.Adam(model.parameters(), lr= .002) #optimizer. There are alternatives such as SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wP9iP8arbV11",
    "outputId": "1113d82b-acad-4780-e4f3-29e765140993"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 1/10], Step [ 50/396], Loss: 1000.0692\n",
      "Epoch [ 1/10], Step [100/396], Loss: 538.8533\n",
      "Epoch [ 1/10], Step [150/396], Loss: 222.4758\n",
      "Epoch [ 1/10], Step [200/396], Loss: 256.2907\n",
      "Epoch [ 1/10], Step [250/396], Loss: 267.9098\n",
      "Epoch [ 1/10], Step [300/396], Loss: 351.7468\n",
      "Epoch [ 1/10], Step [350/396], Loss: 198.0839\n",
      "Epoch [ 2/10], Step [ 50/396], Loss: 237.7429\n",
      "Epoch [ 2/10], Step [100/396], Loss: 350.0895\n",
      "Epoch [ 2/10], Step [150/396], Loss: 171.3892\n",
      "Epoch [ 2/10], Step [200/396], Loss: 213.7456\n",
      "Epoch [ 2/10], Step [250/396], Loss: 185.6146\n",
      "Epoch [ 2/10], Step [300/396], Loss: 277.1415\n",
      "Epoch [ 2/10], Step [350/396], Loss: 855.8748\n",
      "Epoch [ 3/10], Step [ 50/396], Loss: 208.6845\n",
      "Epoch [ 3/10], Step [100/396], Loss: 595.3640\n",
      "Epoch [ 3/10], Step [150/396], Loss: 139.2513\n",
      "Epoch [ 3/10], Step [200/396], Loss: 132.9788\n",
      "Epoch [ 3/10], Step [250/396], Loss: 142.9419\n",
      "Epoch [ 3/10], Step [300/396], Loss: 155.6466\n",
      "Epoch [ 3/10], Step [350/396], Loss: 143.7711\n",
      "Epoch [ 4/10], Step [ 50/396], Loss: 605.3184\n",
      "Epoch [ 4/10], Step [100/396], Loss: 233.2439\n",
      "Epoch [ 4/10], Step [150/396], Loss: 97.3737\n",
      "Epoch [ 4/10], Step [200/396], Loss: 123.3874\n",
      "Epoch [ 4/10], Step [250/396], Loss: 105.7236\n",
      "Epoch [ 4/10], Step [300/396], Loss: 100.0530\n",
      "Epoch [ 4/10], Step [350/396], Loss: 146.1249\n",
      "Epoch [ 5/10], Step [ 50/396], Loss: 563.4905\n",
      "Epoch [ 5/10], Step [100/396], Loss: 198.0635\n",
      "Epoch [ 5/10], Step [150/396], Loss: 92.3492\n",
      "Epoch [ 5/10], Step [200/396], Loss: 77.6551\n",
      "Epoch [ 5/10], Step [250/396], Loss: 98.4597\n",
      "Epoch [ 5/10], Step [300/396], Loss: 83.9525\n",
      "Epoch [ 5/10], Step [350/396], Loss: 80.4968\n",
      "Epoch [ 6/10], Step [ 50/396], Loss: 78.1322\n",
      "Epoch [ 6/10], Step [100/396], Loss: 105.6928\n",
      "Epoch [ 6/10], Step [150/396], Loss: 66.0160\n",
      "Epoch [ 6/10], Step [200/396], Loss: 58.9661\n",
      "Epoch [ 6/10], Step [250/396], Loss: 67.1477\n",
      "Epoch [ 6/10], Step [300/396], Loss: 59.3764\n",
      "Epoch [ 6/10], Step [350/396], Loss: 64.5245\n",
      "Epoch [ 7/10], Step [ 50/396], Loss: 206.8575\n",
      "Epoch [ 7/10], Step [100/396], Loss: 153.9637\n",
      "Epoch [ 7/10], Step [150/396], Loss: 71.2383\n",
      "Epoch [ 7/10], Step [200/396], Loss: 49.5839\n",
      "Epoch [ 7/10], Step [250/396], Loss: 49.9544\n",
      "Epoch [ 7/10], Step [300/396], Loss: 51.7563\n",
      "Epoch [ 7/10], Step [350/396], Loss: 46.9643\n",
      "Epoch [ 8/10], Step [ 50/396], Loss: 41.4844\n",
      "Epoch [ 8/10], Step [100/396], Loss: 61.6352\n",
      "Epoch [ 8/10], Step [150/396], Loss: 32.8524\n",
      "Epoch [ 8/10], Step [200/396], Loss: 32.0924\n",
      "Epoch [ 8/10], Step [250/396], Loss: 36.9032\n",
      "Epoch [ 8/10], Step [300/396], Loss: 35.8453\n",
      "Epoch [ 8/10], Step [350/396], Loss: 87.0917\n",
      "Epoch [ 9/10], Step [ 50/396], Loss: 109.4060\n",
      "Epoch [ 9/10], Step [100/396], Loss: 172.3404\n",
      "Epoch [ 9/10], Step [150/396], Loss: 47.7063\n",
      "Epoch [ 9/10], Step [200/396], Loss: 26.5896\n",
      "Epoch [ 9/10], Step [250/396], Loss: 29.3986\n",
      "Epoch [ 9/10], Step [300/396], Loss: 27.5572\n",
      "Epoch [ 9/10], Step [350/396], Loss: 24.7558\n",
      "Epoch [10/10], Step [ 50/396], Loss: 25.8601\n",
      "Epoch [10/10], Step [100/396], Loss: 40.9479\n",
      "Epoch [10/10], Step [150/396], Loss: 20.2300\n",
      "Epoch [10/10], Step [200/396], Loss: 21.1895\n",
      "Epoch [10/10], Step [250/396], Loss: 24.7656\n",
      "Epoch [10/10], Step [300/396], Loss: 21.6814\n",
      "Epoch [10/10], Step [350/396], Loss: 24.4409\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size=20\n",
    "losses = []\n",
    "acc=[]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (im1, im2, mid) in enumerate(trainloader):\n",
    "        \n",
    "        # we need all our data to be tensor and to be float32 befor giving it to NN to run properly\n",
    "        im1 = torch.from_numpy(np.array(im1, dtype='float32'))\n",
    "        im1 = im1.to(device)\n",
    "       \n",
    "        im2 = torch.from_numpy(np.array(im2, dtype='float32'))\n",
    "        im2 = im2.to(device)\n",
    "        \n",
    "        mid = torch.from_numpy(np.array(mid, dtype='float32'))\n",
    "        mid = mid.to(device)\n",
    "       \n",
    "        # forwad pass\n",
    "        outputs = model(im1, im2)\n",
    "        outputs.to(device)\n",
    "        #outputs = outputs.double()\n",
    "        \n",
    "        # loss: though this is not the actuall loss, it gives a very good insight to our real loss\n",
    "        # clearly, whenever this loss is smaller, real loss is smaller and vice versa. but computing\n",
    "        # real loss function, add huge computation to our network in each iteration. \n",
    "        # I only computed the final accuracy of the model in the next coding parts. \n",
    "        # but could do it here, adding much more computation for each iteration.\n",
    "        loss = criterion(outputs, mid)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # report\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print('Epoch [%2d/%2d], Step [%3d/%3d], Loss: %.4f'\n",
    "                  % (epoch + 1, num_epochs, i + 1, train_size // batch_size, loss.item()))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "-f0gKtg2e-RU",
    "outputId": "e5d5a02f-c696-42ea-b040-7c9dde4d8774"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize= (12,4))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.title('mse loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AG2g-U9ZCbMo"
   },
   "source": [
    "Here, I used all set of two images in test set and produced their outputs and stored them all in a list called Z. \n",
    "\n",
    "After that for each middle real value of test set, I compared it to network value and saw where the argmin was.Consider an example: \n",
    "\n",
    "For example, for the 60th row in testing set, I compared the difference of the actual middle matrix with all values in the list Z and saw where this difference was minimum. If it was for example the Z[23], then it showed that network think that the first two column of the test set is responsible for producing the 60th middle matrix of the test_set. So, it would be wrong.\n",
    "\n",
    "So what I did to measure the acuracy of the model is for each row in test set, I compared the output of the network for it and compared it to all real middle matrices and saw which one is closer to it. \n",
    "\n",
    "Thus, overall we give network an input from test set and we know from which rows it comes. Also, network predict a row responsible for it. Then if these two row indices match, the network has done its work correctly.\n",
    "Remark: I could also do the following that for a middle matrix M, for each image X, compare Y that is most likely match for X for producing M and return best (X,Y) for it. But the way I do has exactly the same result as the function here is linear and can be written in different formats like I did. \n",
    "\n",
    "I write an actual prediction function in final part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "o_872hL-xmGK"
   },
   "outputs": [],
   "source": [
    "#no training, so,no grad required\n",
    "Z=[]\n",
    "with torch.no_grad():\n",
    "    for i, (im1, im2, mid) in enumerate(testloader):\n",
    "        #im1= im1/255\n",
    "        im1= torch.from_numpy(np.array(im1, dtype='float32'))\n",
    "        im1= im1.to(device)\n",
    "\n",
    "\n",
    "        #im2= im2/255\n",
    "        im2= torch.from_numpy(np.array(im2, dtype='float32'))\n",
    "        im2= im2.to(device)\n",
    "\n",
    "        #mid= mid/255\n",
    "        mid= torch.from_numpy(np.array(mid, dtype='float32'))\n",
    "        mid= mid.to(device)\n",
    "\n",
    "        # forwad pass\n",
    "        outputs= model(im1, im2)\n",
    "        Z.append(outputs)\n",
    "#producing a list of indices of the best pair (X,Y) that produces each Z[i] \n",
    "indices=[]\n",
    "for j in range(len(test_data)):\n",
    "    differs=[]\n",
    "    for i in range(len(test_data)):\n",
    "        l= torch.linalg.norm(Z[i].cpu()-test_data[j][2])\n",
    "        differs.append(l)\n",
    "    indices.append(np.argmin(differs))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6i6XHsglnXM",
    "outputId": "2a10edf2-6f02-4b65-cba7-ab265f8f5743"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of model is: 0.9049440847557386\n",
      "number of correct prediction is: 3075 out of overall: 3398 test data\n"
     ]
    }
   ],
   "source": [
    "#computing acuracy of model by computing number of correct predictions out of all \n",
    "num_correct = 0\n",
    "for i in range(len(test_data)):\n",
    "    if indices[i]==np.arange(len(test_data))[i]:\n",
    "        num_correct += 1\n",
    "acc.append(num_correct / len(test_data))   \n",
    "print('accuracy of model is:', num_correct / len(test_data))\n",
    "print('number of correct prediction is:', num_correct,'out of overall:', len(test_data), 'test data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnjcKnp0NM5x"
   },
   "source": [
    "**Naive Prediction limited to only test set**\n",
    "\n",
    "In this part, we have a predicting function that for each input, returns two images that the network think are responsible for producing this input. Of course this is only for test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPnDPBxohMTR"
   },
   "outputs": [],
   "source": [
    "def predicting(middle):\n",
    "    differs=[]\n",
    "    for i in range(len(test_data)):\n",
    "        differs.append(torch.linalg.norm(Z[i].cpu()-middle))\n",
    "    index= np.argmin(differs)\n",
    "    print('your middle is:', middle)\n",
    "    return('the first image is:',test_data[index][0], 'the second image is', test_data[index][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnD4B0GGdr09",
    "outputId": "5cabe773-10f4-4580-b793-16ff1df8526c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your middle is: [175.  173.5 176.5 ... 159.5 151.  140.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('the first image is:',\n",
       " array([201, 209, 226, ..., 197, 193, 181], dtype=uint8),\n",
       " 'the second image is',\n",
       " array([149, 138, 127, ..., 122, 109, 100], dtype=uint8))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a test of how function works\n",
    "predicting(test_data[208][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "En3UZ5xdw8ZV"
   },
   "source": [
    "**Final part:**\n",
    "\n",
    "**Real Prediction:**\n",
    "\n",
    "In this section, I defined a final function that taking any middle matrix Z as an input, it returns both A and B that it things has created our Z.\n",
    "In this stage, we can use any two pictures of our 1000 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1QXpkrhym_b"
   },
   "source": [
    "Building up Query input:\n",
    "You can build up an input here to give it to 'real_prediction'. If you want to test it, just give the 'query' function, indices of first and second image of our sample of 1000 samples. then give the result to 'real_prediction' to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "hgiPTesxy4L3"
   },
   "outputs": [],
   "source": [
    "def query(i,j):\n",
    "    a= torch.from_numpy(np.array(AS[i].flatten(), dtype='float32'))\n",
    "    b= torch.from_numpy(np.array(AS[j].flatten(), dtype='float32'))\n",
    "    c= (a+b)/2\n",
    "    c= c.to(device)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bY-Xfz4TxWye"
   },
   "source": [
    "The way this real_prediction function is work is that for any qurey point (middle matrix Z), for all set of possible images from our 1000 images, it computes all output of the model i.e. all outputs of (X,Y). Then for each of these binary combinations, it compute Norm(model(X,), Z) and find the argmin of this matrix. The indices of this matrix would be our desired outputs i.e. images A and B that are likely to have produced Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "QWtlAnzNyKh4"
   },
   "outputs": [],
   "source": [
    "def real_prediction(Q):\n",
    "    d= np.full((1000,1000), np.inf)\n",
    "    for i in range(1000):\n",
    "\n",
    "        a= torch.from_numpy(np.array(AS[i].flatten(), dtype='float32'))\n",
    "        a= a.to(device)\n",
    "\n",
    "        for j in np.arange(i, 1000):\n",
    "            b= torch.from_numpy(np.array(AS[j].flatten(), dtype='float32'))\n",
    "            b= b.to(device)\n",
    "\n",
    "            o= model(a,b)\n",
    "      \n",
    "            d[i,j]= torch.linalg.norm(o-Q)\n",
    "            #d.to(device)\n",
    "    minimiser= np.ndarray.argmin(d)\n",
    "    I= minimiser // 1000\n",
    "    J= minimiser % 1000\n",
    "    print('first image is:', I , 'th image of our 1000 sample')\n",
    "    print('second image is:', J , 'th image of our 1000 sample')\n",
    "    print('first image is:', S[I])\n",
    "    print('second image is:', S[J])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hriq2ttGyKkh",
    "outputId": "22f91b8c-ba91-44d5-af8f-e7055958b401"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first image is: 14 th image of our 1000 sample\n",
      "second image is: 601 th image of our 1000 sample\n",
      "first image is: [[[133 140 159]\n",
      "  [132 139 158]\n",
      "  [133 140 158]\n",
      "  ...\n",
      "  [134 140 159]\n",
      "  [133 140 158]\n",
      "  [133 140 158]]\n",
      "\n",
      " [[135 142 161]\n",
      "  [134 141 160]\n",
      "  [135 142 160]\n",
      "  ...\n",
      "  [135 142 161]\n",
      "  [135 142 160]\n",
      "  [135 142 160]]\n",
      "\n",
      " [[134 141 160]\n",
      "  [133 140 159]\n",
      "  [134 140 159]\n",
      "  ...\n",
      "  [134 141 159]\n",
      "  [134 140 159]\n",
      "  [134 140 158]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[146 148 154]\n",
      "  [143 145 152]\n",
      "  [142 145 151]\n",
      "  ...\n",
      "  [128 128 134]\n",
      "  [128 129 135]\n",
      "  [113 116 123]]\n",
      "\n",
      " [[162 163 166]\n",
      "  [161 162 165]\n",
      "  [162 163 168]\n",
      "  ...\n",
      "  [111 113 123]\n",
      "  [111 113 123]\n",
      "  [110 113 123]]\n",
      "\n",
      " [[161 162 166]\n",
      "  [160 161 165]\n",
      "  [159 160 164]\n",
      "  ...\n",
      "  [129 132 141]\n",
      "  [128 132 141]\n",
      "  [128 132 141]]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 601",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-f9a2c5783dc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m601\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreal_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-78-3f25aa3c9af4>\u001b[0m in \u001b[0;36mreal_prediction\u001b[0;34m(Q)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'second image is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'th image of our 1000 sample'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'first image is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'second image is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 601"
     ]
    }
   ],
   "source": [
    "#example\n",
    "t= query(14, 601)\n",
    "real_prediction(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FslD32rX0jvm",
    "outputId": "24b8779a-e4a0-48f1-c760-29ffea8362e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first image is: 56 th image of our 1000 sample\n",
      "second image is: 888 th image of our 1000 sample\n",
      "first image is: [[[0 0 2]\n",
      "  [0 0 2]\n",
      "  [0 0 2]\n",
      "  ...\n",
      "  [0 0 2]\n",
      "  [0 0 2]\n",
      "  [0 0 2]]\n",
      "\n",
      " [[0 0 2]\n",
      "  [0 0 2]\n",
      "  [0 0 2]\n",
      "  ...\n",
      "  [0 0 2]\n",
      "  [0 0 2]\n",
      "  [0 0 2]]\n",
      "\n",
      " [[0 0 2]\n",
      "  [0 0 2]\n",
      "  [0 0 2]\n",
      "  ...\n",
      "  [0 0 2]\n",
      "  [0 0 2]\n",
      "  [0 0 2]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 2]\n",
      "  [0 0 2]\n",
      "  [0 0 2]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 2]\n",
      "  [0 0 2]\n",
      "  [0 0 2]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 2]\n",
      "  [0 0 2]\n",
      "  [0 0 2]\n",
      "  ...\n",
      "  [0 0 2]\n",
      "  [0 0 2]\n",
      "  [0 0 2]]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 888",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-7126114b08cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#another example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mr1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m56\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m888\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mreal_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-78-3f25aa3c9af4>\u001b[0m in \u001b[0;36mreal_prediction\u001b[0;34m(Q)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'second image is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'th image of our 1000 sample'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'first image is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'second image is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 888"
     ]
    }
   ],
   "source": [
    "#another example\n",
    "r1= query(56, 888)\n",
    "real_prediction(r1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
